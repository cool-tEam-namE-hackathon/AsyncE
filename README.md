# `AsyncE`

Welcome to your new `AsyncE` project and to the Internet Computer development community. By default, creating a new project adds this README and some template files to your project directory. You can edit these template files to customize your project and to include your own code to speed up the development cycle.

To get started, you might want to explore the project directory structure and the default configuration file. Working with this project in your development environment will not affect any production deployment or identity tokens.

To learn more before you start working with `AsyncE`, see the following documentation available online:

-   [Quick Start](https://internetcomputer.org/docs/current/developer-docs/setup/deploy-locally)
-   [SDK Developer Tools](https://internetcomputer.org/docs/current/developer-docs/setup/install)
-   [Rust Canister Development Guide](https://internetcomputer.org/docs/current/developer-docs/backend/rust/)
-   [ic-cdk](https://docs.rs/ic-cdk)
-   [ic-cdk-macros](https://docs.rs/ic-cdk-macros)
-   [Candid Introduction](https://internetcomputer.org/docs/current/developer-docs/backend/candid/)

If you want to start working on your project right away, you might want to try the following commands:

```bash
cd AsyncE/
dfx help
dfx canister --help
```

## Running the project locally

If you want to test your project locally, you can use the following commands:

```bash
# Starts the replica, running in the background
dfx start --background

# Deploys your canisters to the replica and generates your candid interface
dfx deploy
```

Once the job completes, your application will be available at `http://localhost:4943?canisterId={asset_canister_id}`.

If you have made changes to your backend canister, you can generate a new candid interface with

```bash
npm run generate
```

at any time. This is recommended before starting the frontend development server, and will be run automatically any time you run `dfx deploy`.

If you are making frontend changes, you can start a development server with

```bash
npm start
```

Which will start a server at `http://localhost:8080`, proxying API requests to the replica at port 4943.

### Note on frontend environment variables

If you are hosting frontend code somewhere without using DFX, you may need to make one of the following adjustments to ensure your project does not fetch the root key in production:

-   set`DFX_NETWORK` to `ic` if you are using Webpack
-   use your own preferred method to replace `process.env.DFX_NETWORK` in the autogenerated declarations
    -   Setting `canisters -> {asset_canister_id} -> declarations -> env_override to a string` in `dfx.json` will replace `process.env.DFX_NETWORK` with the string in the autogenerated declarations
-   Write your own `createActor` constructor

### Setting Up OpenAI Whisper Locally (For Offline Use)

- Download OpenAI Whisper model, encoder.json, and vobac.bpe
- Put the fiels <Model Name>.pt, encoder.json, and vocab.bpe in the same folder
- Edit the file `~/.local/lib/python3.10/site-packages/tiktoken_ext/openai_public.py` (if you are on Linux / MacOS) or `C:\Users\<Your Username>\AppData\Local\Programs\Python\Python310-32\Lib\site-packagespython3.9/site-packages/tiktoken_ext/openai_public.py` (if you are on Windows)
- Edit the previously located `openai_public.py` file to change the gpt2 function to the following:
```py
def gpt2():
    mergeable_ranks = data_gym_to_mergeable_bpe_ranks(
        vocab_bpe_file="[Folder Path]/vocab.bpe",
        encoder_json_file="[Folder Path]/encoder.json",
    )
```
